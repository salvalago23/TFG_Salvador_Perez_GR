{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from envs.GridMaps import *\n",
    "from utilities.transitionDatasetGeneration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = \"14x14\"                     #Tamanho del grid '5x5' o '14x14'\n",
    "store = True                        #'True' para guardar el ensemble generado en la carpeta\n",
    "\n",
    "if shape == \"5x5\":\n",
    "    maze = maze5x5[\"maze\"]          #Nombre del mapa que se va a utilizar\n",
    "    n_epochs = 15000                #Numero de epocas a entrenar cada modelo\n",
    "    folder_name = \"5x5_5_model\"     #Nombre de la carpeta donde se guardan los modelos\n",
    "    n_models = 5                    #Numero de modelos en el ensemble\n",
    "    hidden_size = 32                #Numero de neuronas en las capas ocultas de los modelos\n",
    "\n",
    "elif shape == \"14x14\":              \n",
    "    maze = maze14x14[\"maze\"]        #Nombre del mapa que se va a utilizar\n",
    "    n_epochs = 120000               #Numero de epocas a entrenar cada modelo\n",
    "    folder_name = \"5_model\"         #Nombre de la carpeta donde se guardan los modelos\n",
    "    n_models = 5                    #Numero de modelos en el ensemble\n",
    "    hidden_size = 512               #Numero de neuronas en las capas ocultas de los modelos\n",
    "    \n",
    "#Generacion del dataset offline\n",
    "train_transitions, val_transitions = transition_generator(maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [52:42<00:00, 37.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained successfully!\n",
      "Final loss: 7.184115474956343e-06\n",
      "\n",
      "Training model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [47:32<00:00, 42.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained successfully!\n",
      "Final loss: 6.542316259583458e-05\n",
      "\n",
      "Training model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [47:27<00:00, 42.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained successfully!\n",
      "Final loss: 4.470402927836403e-05\n",
      "\n",
      "Training model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [47:29<00:00, 42.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained successfully!\n",
      "Final loss: 6.841804861323908e-05\n",
      "\n",
      "Training model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [47:45<00:00, 41.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained successfully!\n",
      "Final loss: 1.0458199540153146e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_arr = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    print(f\"Training model {i+1}...\")\n",
    "\n",
    "    model = ModelTrainer(train_transitions, val_transitions, n_epochs, hidden_size, rand_seed=True)\n",
    "\n",
    "    model.fit()\n",
    "    models_arr.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if store: store_models(models_arr, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION:\n",
      "\n",
      "Using device: cuda\n",
      "[5 4]           [5 5]\n",
      "[5 4]           [5 5]\n",
      "[5 4]           [5 5]\n",
      "[5 4]           [5 5]\n",
      "[5 4]           [5 5]\n",
      "\n",
      "\n",
      "Mean of raw values:\n",
      "[4.9993773 3.9983373]\n",
      "[5.0009923 4.9991593]\n",
      "\n",
      "\n",
      "Std of raw values:\n",
      "[0.00542308 0.00251136]       0.0059763477\n",
      "[0.00379623 0.00423822]       0.005689801\n"
     ]
    }
   ],
   "source": [
    "print('\\nEVALUATION:\\n')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "arr1 = []\n",
    "arr1_raw = []\n",
    "arr2 = []\n",
    "arr2_raw = []\n",
    "\n",
    "for model in models_arr:\n",
    "    # Single predictions\n",
    "    with torch.no_grad():\n",
    "        # Move the input data to the GPU\n",
    "        inp1 = torch.FloatTensor([[5, 3, 3]]).to(device)\n",
    "        inp2 = torch.FloatTensor([[5, 4, 3]]).to(device)\n",
    "        \n",
    "        # Perform inference on the GPU\n",
    "        resultado1 = model.model(inp1)\n",
    "        resultado2 = model.model(inp2)\n",
    "        \n",
    "        # Move the result back to CPU and convert to numpy\n",
    "        resultado1 = resultado1.cpu().detach().numpy()\n",
    "        resultado2 = resultado2.cpu().detach().numpy()\n",
    "\n",
    "        arr1.append(np.int32(np.round(resultado1[0])))\n",
    "        arr1_raw.append(resultado1[0])\n",
    "        arr2.append(np.int32(np.round(resultado2[0])))\n",
    "        arr2_raw.append(resultado2[0])\n",
    "        \n",
    "for elem, elem2 in zip(arr1, arr2):\n",
    "    print(elem, '         ', elem2)\n",
    "\n",
    "#whats the mean and the std of the raw values?\n",
    "print('\\n')\n",
    "print('Mean of raw values:')\n",
    "print(np.mean(arr1_raw, axis=0))\n",
    "print(np.mean(arr2_raw, axis=0))\n",
    "print('\\n')\n",
    "print('Std of raw values:')\n",
    "print(np.std(arr1_raw, axis=0), '     ', np.linalg.norm(np.std(arr1_raw, axis=0)))\n",
    "print(np.std(arr2_raw, axis=0), '     ', np.linalg.norm(np.std(arr2_raw, axis=0)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
