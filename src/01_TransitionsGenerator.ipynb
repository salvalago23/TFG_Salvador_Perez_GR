{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#from envs.environments import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, fc1_unit=None, fc2_unit=None):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        if fc1_unit is None:\n",
    "            self.big = False\n",
    "            self.fc1 = nn.Linear(input_size, 64)\n",
    "            self.fc2 = nn.Linear(64, output_size)\n",
    "        else:\n",
    "            self.big = True\n",
    "            self.fc1 = nn.Linear(input_size, fc1_unit)\n",
    "            self.fc2 = nn.Linear(fc1_unit, fc2_unit)\n",
    "            self.fc3 = nn.Linear(fc2_unit, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "\n",
    "        if not self.big:\n",
    "            x = self.fc2(x)\n",
    "        else:\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_generator(maze, with_walls = True):\n",
    "    transiciones = []\n",
    "\n",
    "    n_rows, n_cols = len(maze), len(maze[0])\n",
    "\n",
    "    for y in range(n_rows):\n",
    "        for x in range(n_cols):\n",
    "            # Si la casilla actual es un muro o una casilla 'x' (forzada a no demostracion),\n",
    "            # no se puede guardar la transición\n",
    "            if maze[y][x] != '#' and maze[y][x] != 'x':\n",
    "                for a in range(4):\n",
    "                    if a == 0:  # Mover hacia el norte\n",
    "                        y1, x1 = max(0, y - 1), x\n",
    "                    elif a == 1:  # Mover hacia el sur\n",
    "                        y1, x1 = min(n_rows - 1, y + 1), x\n",
    "                    elif a == 2:  # Mover hacia el oeste\n",
    "                        y1, x1 = y, max(0, x - 1)\n",
    "                    elif a == 3:  # Mover hacia el este\n",
    "                        y1, x1 = y, min(n_cols - 1, x + 1)\n",
    "\n",
    "                    # Si la casilla siguiente es un muro y el booleano es válido,\n",
    "                    # se debe guardar la transición de la casilla actual a sí misma\n",
    "                    if maze[y1][x1] == '#':\n",
    "                        if with_walls:\n",
    "                            transiciones.append([y, x, a, y, x])\n",
    "                    # Si la casilla siguiente es una casilla 'x' no vamos a guardar ninguna transición\n",
    "                    elif maze[y1][x1] == 'x':\n",
    "                        pass\n",
    "                    # Si la siguiente no es ninguna de las anteriores, se guarda la transición\n",
    "                    else:\n",
    "                        transiciones.append([y, x, a, y1, x1])\n",
    "\n",
    "    return transiciones\n",
    "\n",
    "def transitions_families_generator_BASIC(transiciones_iniciales, porcentaje_retencion, n):\n",
    "    n_transiciones_iniciales = len(transiciones_iniciales)\n",
    "    m = int((1 - porcentaje_retencion) * n_transiciones_iniciales)\n",
    "\n",
    "    nuevos_arrays = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Crear una copia de las transiciones iniciales\n",
    "        nuevas_transiciones = transiciones_iniciales.copy()\n",
    "\n",
    "        # Eliminar aleatoriamente M transiciones\n",
    "        transiciones_a_eliminar = random.sample(nuevas_transiciones, m)\n",
    "        for t in transiciones_a_eliminar:\n",
    "            nuevas_transiciones.remove(t)\n",
    "\n",
    "        nuevos_arrays.append(nuevas_transiciones)\n",
    "\n",
    "    return nuevos_arrays\n",
    "\n",
    "\n",
    "# Misma función que la anterior pero con un porcentaje de retención fijo del 66%\n",
    "# y que después genera el otro 33% de transiciones con repeticiones de las que ya tiene\n",
    "# Al final tendrá el mismo numero de transiciones que la lista original\n",
    "def transitions_families_generator_WITH_REPETITION(transiciones_iniciales, n):\n",
    "    n_transiciones_iniciales = len(transiciones_iniciales)\n",
    "    n_borradas = int((1 - 0.66) * n_transiciones_iniciales)\n",
    "    \n",
    "    nuevos_arrays = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Crear una copia de las transiciones iniciales\n",
    "        nuevas_transiciones = transiciones_iniciales.copy()\n",
    "\n",
    "        # Eliminar aleatoriamente 'n_retenidas' transiciones\n",
    "        transiciones_a_eliminar = random.sample(nuevas_transiciones, n_borradas)\n",
    "        for t in transiciones_a_eliminar:\n",
    "            nuevas_transiciones.remove(t)\n",
    "\n",
    "        # Repetir aleatoriamente 'n_borradas' transiciones\n",
    "        transiciones_a_repetir = random.sample(nuevas_transiciones, n_borradas)\n",
    "        nuevas_transiciones.extend(transiciones_a_repetir)\n",
    "\n",
    "        nuevos_arrays.append(nuevas_transiciones)\n",
    "\n",
    "    return nuevos_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transitions_families_generator_FULLY_REPRESENTED(transiciones_iniciales, n):\n",
    "    n_transiciones_iniciales = len(transiciones_iniciales)\n",
    "    n_subset = int(0.66 * n_transiciones_iniciales)\n",
    "\n",
    "    nuevos_arrays = []\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        # Crear una copia de las transiciones iniciales\n",
    "        nuevas_transiciones = transiciones_iniciales.copy()\n",
    "        \n",
    "        start_index = (i * n_subset) % len(nuevas_transiciones)\n",
    "        end_index = (start_index + n_subset) % len(nuevas_transiciones)\n",
    "\n",
    "        if start_index < end_index:\n",
    "            nuevas_transiciones = nuevas_transiciones[start_index:end_index]\n",
    "        else:\n",
    "            nuevas_transiciones = nuevas_transiciones[start_index:] + nuevas_transiciones[:end_index]        \n",
    "\n",
    "        # Repetir aleatoriamente 'n_borradas' transiciones\n",
    "        transiciones_a_repetir = random.sample(nuevas_transiciones, n_transiciones_iniciales - n_subset)\n",
    "        nuevas_transiciones.extend(transiciones_a_repetir)\n",
    "\n",
    "        nuevos_arrays.append(nuevas_transiciones)\n",
    "\n",
    "    return nuevos_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_original_transitions(all_transitions, new_transitions):\n",
    "    # Aplanar la lista de sublistas\n",
    "    flattened_new_transitions = [item for sublist in new_transitions for item in sublist]\n",
    "\n",
    "    # Inicializar un diccionario para contar las transiciones originales\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    # Contar la frecuencia de cada transición original\n",
    "    for transition in flattened_new_transitions:\n",
    "        counts[tuple(transition)] += 1\n",
    "\n",
    "    index = 1\n",
    "    # Imprimir los resultados\n",
    "    for original_transition in all_transitions:\n",
    "        count = counts.get(tuple(original_transition), 0)\n",
    "        print(f\"{index} Transición: {original_transition}, Apariciones: {count}\")\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FamiliaTransiciones:\n",
    "    def __init__(self, id, shape, T):\n",
    "        self.id = id\n",
    "        self.shape = shape\n",
    "\n",
    "        self.T = T\n",
    "        \n",
    "        self.sy_values = np.array([], dtype = np.float32)\n",
    "        self.sx_values = np.array([], dtype = np.float32)\n",
    "        self.a_values = np.array([], dtype = np.float32)\n",
    "        self.sy1_values = np.array([], dtype = np.float32)\n",
    "        self.sx1_values = np.array([], dtype = np.float32)\n",
    "\n",
    "        self.input_data = None\n",
    "        self.target_data = None\n",
    "\n",
    "        self.X_train_tensor = None\n",
    "        self.X_test_tensor = None\n",
    "        self.y_train_tensor = None\n",
    "        self.y_test_tensor = None\n",
    "\n",
    "        if shape == \"5x5\":\n",
    "            self.model = NeuralNetwork(3, 2)\n",
    "            self.n_epochs = 5000\n",
    "        elif shape == \"14x14\":\n",
    "            self.model = NeuralNetwork(3, 2, 128, 64)\n",
    "            self.n_epochs = 10000\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters())\n",
    "        self.losses = []\n",
    "\n",
    "        self.generate_arrays()\n",
    "    \n",
    "\n",
    "    def generate_arrays(self):\n",
    "        for t in self.T:\n",
    "            self.sy_values = np.append(self.sy_values, t[0])\n",
    "            self.sx_values = np.append(self.sx_values, t[1])\n",
    "            self.a_values = np.append(self.a_values, t[2])\n",
    "            self.sy1_values = np.append(self.sy1_values, t[3])\n",
    "            self.sx1_values = np.append(self.sx1_values, t[4])\n",
    "\n",
    "        self.input_data = np.column_stack((self.sy_values, self.sx_values, self.a_values))\n",
    "        self.target_data = np.column_stack((self.sy1_values, self.sx1_values))\n",
    "\n",
    "    def train(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.input_data, self.target_data, test_size=0.05)\n",
    "        \n",
    "        self.X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        self.y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        self.X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        self.y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        for _ in range(self.n_epochs):\n",
    "            # Forward pass\n",
    "            outputs = self.model(self.X_train_tensor)\n",
    "            loss = self.criterion(outputs, self.y_train_tensor)\n",
    "            \n",
    "            # Backpropagation and optimization\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            self.losses.append(loss.item())\n",
    "        \n",
    "        print(\"Trained successfully!\")\n",
    "        print(f'Final loss: {self.losses[-1]}\\n')\n",
    "\n",
    "        #save the model with info of the shape and the id\n",
    "        torch.save(self.model.state_dict(), f'../data/offline_models/{self.shape}_{self.id}.pt')\n",
    "\n",
    "    def test_loss(self):\n",
    "        with torch.no_grad():\n",
    "            test_outputs = self.model(self.X_test_tensor)\n",
    "            test_loss = self.criterion(test_outputs, self.y_test_tensor)\n",
    "            print(f'Test loss: {test_loss.item()}')\n",
    "\n",
    "    def show_loss(self):\n",
    "        plt.xlabel(\"# Epoch\")\n",
    "        plt.ylabel(\"Loss Magnitude\")\n",
    "        plt.plot(self.losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze5x5 = { \"starting_pos\": [[0,0], [2,0], [4,0]],\n",
    "             \"maze\":[\n",
    "                    ['x', 'x', '#', 'x', 'G'],#0            0\n",
    "                    ['x', 'x', '#', 'x', '.'],#1            ↑\n",
    "                    ['x', '.', '.', '.', '.'],#2         2 ← → 3\n",
    "                    ['.', '.', '#', 'x', 'x'],#3            ↓\n",
    "                    ['S', '.', '#', 'x', 'x'],#4            1\n",
    "                    # 0    1    2    3    4\n",
    "                    ]\n",
    "        }\n",
    "\n",
    "\"\"\"maze5x5 = { \"starting_pos\": [[0,0], [2,0], [4,0]],\n",
    "             \"maze\":[\n",
    "                    ['x', 'x', '#', '#', 'x', '.', '.', 'G'],#0\n",
    "                    ['x', 'x', '#', '#', 'x', '.', '.', 'x'],#1\n",
    "                    ['x', 'x', '#', '#', 'x', 'x', '.', '.'],#2\n",
    "                    ['x', '.', '.', '.', '.', 'x', 'x', '.'],#3\n",
    "                    ['x', '.', '.', '#', '.', 'x', 'x', '.'],#4\n",
    "                    ['x', '.', '.', '#', '.', '.', '.', '.'],#5\n",
    "                    ['.', '.', '#', '#', '#', 'x', 'x', 'x'],#6\n",
    "                    ['S', '.', '#', '#', '#', 'x', 'x', 'x'],#7\n",
    "                    # 0    1    2    3    4    5    6    7\n",
    "                    ]\n",
    "        }\"\"\"\n",
    "\n",
    "maze14x14 = { \"starting_pos\": [[0,0], [5,0], [7,0], [13,0], [13,5], [13,8], [13,11]],\n",
    "             \"maze\":[\n",
    "                    ['x', '#', 'x', 'x', '.', '.', '.', '.', '#', '#', '#', '#', '.', 'G'],#0\n",
    "                    ['x', '#', 'x', '#', '#', '#', '.', '.', '.', 'x', 'x', 'x', '.', '.'],#1\n",
    "                    ['x', 'x', 'x', 'x', '.', '#', '.', '.', '#', 'x', 'x', '#', '.', '.'],#2\n",
    "                    ['x', '#', '#', '#', '.', '#', '.', '.', '.', 'x', 'x', '#', '.', '.'],#3\n",
    "                    ['x', 'x', '#', 'x', '.', '#', '#', '#', '#', '#', '.', '#', '#', '.'],#4\n",
    "                    ['x', 'x', 'x', 'x', '.', '.', '.', 'x', 'x', 'x', '.', '.', '#', '.'],#5\n",
    "                    ['#', '#', '#', '#', '#', '.', '#', '#', 'x', 'x', '.', '.', '#', '.'],#6\n",
    "                    ['.', '.', '.', '.', '#', '.', '.', '#', 'x', 'x', '.', '.', '.', '.'],#7\n",
    "                    ['.', '.', '.', '.', '#', '.', '.', '#', '.', '#', '.', '#', '#', '#'],#8\n",
    "                    ['#', '.', '#', '.', '#', '.', '#', '#', '.', '#', '.', '.', '.', '.'],#9\n",
    "                    ['.', '.', '#', '.', '.', '.', '#', '.', '.', '.', '.', '.', '.', '.'],#10\n",
    "                    ['.', '#', '#', 'x', '#', '.', '.', '.', '.', '#', '.', '#', '#', '.'],#11\n",
    "                    ['.', 'x', 'x', 'x', '#', '#', '.', '#', '.', '#', '.', '.', '#', '.'],#12\n",
    "                    ['S', 'x', '#', 'x', '#', '.', '.', '#', '.', '#', '.', '.', '#', '.'],#13\n",
    "                    # 0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
    "                    ]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = \"14x14\"\n",
    "\n",
    "if shape == \"5x5\":\n",
    "    maze = maze5x5[\"maze\"]\n",
    "elif shape == \"14x14\":\n",
    "    maze = maze14x14[\"maze\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transitions = transition_generator(maze)\n",
    "\n",
    "keep = 0.2  # Retener un % de las transiciones (0 a 1)\n",
    "\n",
    "#Este siguiente parámetro debe ser impar para que haya menos posibilidades de empate\n",
    "if shape == \"5x5\":\n",
    "    n = 9  # Generar N nuevos arrays\n",
    "elif shape == \"14x14\":\n",
    "    n = 9\n",
    "\n",
    "\n",
    "#new_transitions = transitions_families_generator(all_transitions, keep, n)\n",
    "\n",
    "new_transitions = transitions_families_generator_FULLY_REPRESENTED(all_transitions, n)\n",
    "\n",
    "#print(\"Long. del array original:\", len(all_transitions))\n",
    "\n",
    "#for transitions in new_transitions:\n",
    "    #print(\"Long. de nuevo array\", len(transitions))\n",
    "    #for i in range(5):\n",
    "        #print(transitions[i])\n",
    "    #print(\"-\"*17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for f in families_arr:\\n    print(\"sy_values: \", f.sy_values)\\n    print(\"sx_values: \", f.sx_values)\\n    print(\"a_values:  \", f.a_values)\\n    print(\"sy1_values:\", f.sy1_values)\\n    print(\"sx1_values:\", f.sx1_values)\\n    print(\"-\" * 50 + \"\\n\")'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "families_arr = []\n",
    "\n",
    "for i in range(len(new_transitions)):\n",
    "    families_arr.append(FamiliaTransiciones(i, shape, new_transitions[i]))\n",
    "\n",
    "\"\"\"for f in families_arr:\n",
    "    print(\"sy_values: \", f.sy_values)\n",
    "    print(\"sx_values: \", f.sx_values)\n",
    "    print(\"a_values:  \", f.a_values)\n",
    "    print(\"sy1_values:\", f.sy1_values)\n",
    "    print(\"sx1_values:\", f.sx1_values)\n",
    "    print(\"-\" * 50 + \"\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.03653372824192047\n",
      "\n",
      "Training model 2 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.047162674367427826\n",
      "\n",
      "Training model 3 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.06810775399208069\n",
      "\n",
      "Training model 4 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.044544585049152374\n",
      "\n",
      "Training model 5 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.04105772823095322\n",
      "\n",
      "Training model 6 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.06051182746887207\n",
      "\n",
      "Training model 7 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.03641342744231224\n",
      "\n",
      "Training model 8 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.045642923563718796\n",
      "\n",
      "Training model 9 / 9\n",
      "Trained successfully!\n",
      "Final loss: 0.05723721906542778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in families_arr:\n",
    "    print(\"Training model\", f.id + 1, \"/\", len(families_arr))\n",
    "    f.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08487910777330399\n",
      "Test loss: 0.07698927819728851\n",
      "Test loss: 0.08014411479234695\n",
      "Test loss: 0.07774621248245239\n",
      "Test loss: 0.21170277893543243\n",
      "Test loss: 0.12452129274606705\n",
      "Test loss: 0.09232393652200699\n",
      "Test loss: 0.10990975797176361\n",
      "Test loss: 0.10455727577209473\n"
     ]
    }
   ],
   "source": [
    "for f in families_arr:\n",
    "    f.test_loss()\n",
    "    #f.show_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [12, 0, 0]\n",
      "Predicciones: \n",
      "[13, 0]:  11.111 %\n",
      "[11, 0]:  66.667 %\n",
      "[9, 0]:  11.111 %\n",
      "[8, 1]:  11.111 %\n",
      "--------------------------------------------------\n",
      "\n",
      "Input: [12, 0, 1]\n",
      "Predicciones: \n",
      "[14, 1]:  11.111 %\n",
      "[13, 0]:  66.667 %\n",
      "[10, 0]:  11.111 %\n",
      "[11, 1]:  11.111 %\n",
      "--------------------------------------------------\n",
      "\n",
      "Input: [12, 0, 2]\n",
      "Predicciones: \n",
      "[13, 0]:  11.111 %\n",
      "[12, 0]:  66.667 %\n",
      "[11, 0]:  22.222 %\n",
      "--------------------------------------------------\n",
      "\n",
      "Input: [12, 0, 3]\n",
      "Predicciones: \n",
      "[13, 1]:  11.111 %\n",
      "[12, 0]:  55.556 %\n",
      "[11, 1]:  22.222 %\n",
      "[12, 1]:  11.111 %\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y, x = 12, 0\n",
    "\n",
    "for i in range(4):\n",
    "    posibilidades = []\n",
    "\n",
    "    test_input = torch.tensor([[float(y), float(x), float(i)]], dtype=torch.float32)\n",
    "    \n",
    "    print(\"Input: \" + str([y, x, i]))\n",
    "\n",
    "    for i in range(len(families_arr)):\n",
    "        resultado = families_arr[i].model(test_input)\n",
    "        resultado = resultado.detach().numpy()\n",
    "        posibilidades.append([round(resultado[0][0]), round(resultado[0][1])])\n",
    "    \n",
    "    #print(\"Estados futuros predichos: \" + str(posibilidades))\n",
    "\n",
    "    #Calculo el porcentaje de veces que aparece cada posibilidad\n",
    "    probability_dict = {str(posibilidades.count(p)/len(posibilidades)*100) + \"%\": p for p in posibilidades}\n",
    "\n",
    "    probability_dict = {}\n",
    "    for p in posibilidades:\n",
    "        if not str(p) in probability_dict:\n",
    "            probability_dict[str(p)] = str(posibilidades.count(p)/len(posibilidades))\n",
    "\n",
    "\n",
    "    print(\"Predicciones: \")\n",
    "    for p in probability_dict:\n",
    "        print(p + \": \", round(float(probability_dict[p])*100, 3),\"%\")\n",
    "\n",
    "    #print(\"Probabilidad \" + str(p) + \": \" + str(posibilidades.count(p)/len(posibilidades)*100) + \"%\")\n",
    "    \n",
    "    print(\"--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [2, 3, 0]\n",
      "Predicciones: \n",
      "[2, 3]:  55.556 %\n",
      "[1, 3]:  33.333 %\n",
      "[3, 3]:  11.111 %\n",
      "--------------------------------------------------\n",
      "\n",
      "Input: [2, 3, 1]\n",
      "Predicciones: \n",
      "[3, 3]:  66.667 %\n",
      "[3, 2]:  22.222 %\n",
      "[2, 2]:  11.111 %\n",
      "--------------------------------------------------\n",
      "\n",
      "Input: [2, 3, 2]\n",
      "Predicciones: \n",
      "[2, 3]:  55.556 %\n",
      "[3, 2]:  22.222 %\n",
      "[2, 2]:  22.222 %\n",
      "--------------------------------------------------\n",
      "\n",
      "Input: [2, 3, 3]\n",
      "Predicciones: \n",
      "[2, 3]:  44.444 %\n",
      "[2, 4]:  22.222 %\n",
      "[2, 1]:  11.111 %\n",
      "[2, 2]:  11.111 %\n",
      "[1, 5]:  11.111 %\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y, x = 2, 3\n",
    "\n",
    "for i in range(4):\n",
    "    posibilidades = []\n",
    "\n",
    "    test_input = torch.tensor([[float(y), float(x), float(i)]], dtype=torch.float32)\n",
    "    \n",
    "    print(\"Input: \" + str([y, x, i]))\n",
    "\n",
    "    for i in range(len(families_arr)):\n",
    "        resultado = families_arr[i].model(test_input)\n",
    "        resultado = resultado.detach().numpy()\n",
    "        posibilidades.append([round(resultado[0][0]), round(resultado[0][1])])\n",
    "    \n",
    "    #Calculo el porcentaje de veces que aparece cada posibilidad\n",
    "    probability_dict = {str(posibilidades.count(p)/len(posibilidades)*100) + \"%\": p for p in posibilidades}\n",
    "\n",
    "    probability_dict = {}\n",
    "    for p in posibilidades:\n",
    "        if not str(p) in probability_dict:\n",
    "            probability_dict[str(p)] = str(posibilidades.count(p)/len(posibilidades))\n",
    "\n",
    "    #Ordeno el diccionario por las probabilidades de mayor a menor\n",
    "    probability_dict = {k: v for k, v in sorted(probability_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    highest_probability = list(probability_dict.keys())[0]\n",
    "    #obtener el valor de la probabilidad del mas alto\n",
    "    valor = float(list(probability_dict.values())[0])\n",
    "\n",
    "    #convertirla de nuevo a lista\n",
    "    highest_probability = highest_probability.replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")\n",
    "\n",
    "    highest_probability = [highest_probability[0], highest_probability[1]]\n",
    "    \n",
    "    print(\"Predicciones: \")\n",
    "    for p in probability_dict:\n",
    "        print(p + \": \", round(float(probability_dict[p])*100, 3),\"%\")\n",
    "\n",
    "    #print(\"Probabilidad \" + str(p) + \": \" + str(posibilidades.count(p)/len(posibilidades)*100) + \"%\")\n",
    "    \n",
    "    print(\"--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#y, x = 2, 3\\n# Abre un archivo en modo de anexar (\\'a\\')\\nwith open(\\'archivo.txt\\', \\'a\\') as archivo:\\n    #archivo.write(\"e\")\\n\\n    for fila in maze:\\n        for x in range(5):\\n            if fila[x] == \\'x\\':\\n                y = maze.index(fila)\\n                print(\"y: \", y, \"x: \", x)\\n\\n                archivo.write(\"Casilla \" + str(y) + \", \" + str(x) + \"\\n\")\\n\\n                for i in range(4):\\n                    posibilidades = []\\n\\n                    test_input = torch.tensor([[float(y), float(x), float(i)]], dtype=torch.float32)\\n                    \\n                    print(\"Input: \" + str([y, x, i]))\\n                    archivo.write(\"Action: \" + str(i) + \"\\n\")\\n                    for i in range(len(families_arr)):\\n                        resultado = families_arr[i].model(test_input)\\n                        resultado = resultado.detach().numpy()\\n                        posibilidades.append([round(resultado[0][0]), round(resultado[0][1])])\\n                    \\n                    #Calculo el porcentaje de veces que aparece cada posibilidad\\n                    probability_dict = {str(posibilidades.count(p)/len(posibilidades)*100) + \"%\": p for p in posibilidades}\\n\\n                    probability_dict = {}\\n                    for p in posibilidades:\\n                        if not str(p) in probability_dict:\\n                            probability_dict[str(p)] = str(posibilidades.count(p)/len(posibilidades))\\n\\n                    #Ordeno el diccionario por las probabilidades de mayor a menor\\n                    probability_dict = {k: v for k, v in sorted(probability_dict.items(), key=lambda item: item[1], reverse=True)}\\n                    \\n                    highest_probability = list(probability_dict.keys())[0]\\n                    #obtener el valor de la probabilidad del mas alto\\n                    valor = float(list(probability_dict.values())[0])\\n\\n                    #convertirla de nuevo a lista\\n                    highest_probability = highest_probability.replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")\\n\\n                    highest_probability = [highest_probability[0], highest_probability[1]]\\n                    \\n                    archivo.write(\"Predicciones: \")\\n                    for p in probability_dict:\\n                        archivo.write(p + \": \"+ str(round(float(probability_dict[p])*100, 3))+\"%\\n\")\\n\\n                    #print(\"Probabilidad \" + str(p) + \": \" + str(posibilidades.count(p)/len(posibilidades)*100) + \"%\")\\n                    \\n                    archivo.write(\"--------------------------------------------------\\n\")\\n                archivo.write(\"\\n\")'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#y, x = 2, 3\n",
    "# Abre un archivo en modo de anexar ('a')\n",
    "with open('archivo.txt', 'a') as archivo:\n",
    "    #archivo.write(\"e\")\n",
    "\n",
    "    for fila in maze:\n",
    "        for x in range(5):\n",
    "            if fila[x] == 'x':\n",
    "                y = maze.index(fila)\n",
    "                print(\"y: \", y, \"x: \", x)\n",
    "\n",
    "                archivo.write(\"Casilla \" + str(y) + \", \" + str(x) + \"\\n\")\n",
    "\n",
    "                for i in range(4):\n",
    "                    posibilidades = []\n",
    "\n",
    "                    test_input = torch.tensor([[float(y), float(x), float(i)]], dtype=torch.float32)\n",
    "                    \n",
    "                    print(\"Input: \" + str([y, x, i]))\n",
    "                    archivo.write(\"Action: \" + str(i) + \"\\n\")\n",
    "                    for i in range(len(families_arr)):\n",
    "                        resultado = families_arr[i].model(test_input)\n",
    "                        resultado = resultado.detach().numpy()\n",
    "                        posibilidades.append([round(resultado[0][0]), round(resultado[0][1])])\n",
    "                    \n",
    "                    #Calculo el porcentaje de veces que aparece cada posibilidad\n",
    "                    probability_dict = {str(posibilidades.count(p)/len(posibilidades)*100) + \"%\": p for p in posibilidades}\n",
    "\n",
    "                    probability_dict = {}\n",
    "                    for p in posibilidades:\n",
    "                        if not str(p) in probability_dict:\n",
    "                            probability_dict[str(p)] = str(posibilidades.count(p)/len(posibilidades))\n",
    "\n",
    "                    #Ordeno el diccionario por las probabilidades de mayor a menor\n",
    "                    probability_dict = {k: v for k, v in sorted(probability_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "                    \n",
    "                    highest_probability = list(probability_dict.keys())[0]\n",
    "                    #obtener el valor de la probabilidad del mas alto\n",
    "                    valor = float(list(probability_dict.values())[0])\n",
    "\n",
    "                    #convertirla de nuevo a lista\n",
    "                    highest_probability = highest_probability.replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")\n",
    "\n",
    "                    highest_probability = [highest_probability[0], highest_probability[1]]\n",
    "                    \n",
    "                    archivo.write(\"Predicciones: \")\n",
    "                    for p in probability_dict:\n",
    "                        archivo.write(p + \": \"+ str(round(float(probability_dict[p])*100, 3))+\"%\\n\")\n",
    "\n",
    "                    #print(\"Probabilidad \" + str(p) + \": \" + str(posibilidades.count(p)/len(posibilidades)*100) + \"%\")\n",
    "                    \n",
    "                    archivo.write(\"--------------------------------------------------\\n\")\n",
    "                archivo.write(\"\\n\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
